{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b979f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aakashahamed/anaconda3/envs/rsenv/lib/python3.8/site-packages/numba/core/decorators.py:255: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import rasterio as rio\n",
    "import geopandas as gp\n",
    "\n",
    "import fiona \n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tqdm import tqdm\n",
    "from PyIF import te_compute as te\n",
    "from sklearn import metrics\n",
    "\n",
    "from osgeo import gdal, osr, ogr\n",
    "from tqdm import tqdm\n",
    "from scipy import stats, spatial, signal, fftpack\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd71966",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gp.read_file(\"../shape/sierra_catchments.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8f3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_raster(array,gdf,outfn):\n",
    "\t'''\n",
    "\tconverts a numpy array and a geopandas gdf to a geotiff\n",
    "\tData values are stored in np.array\n",
    "\tspatial coordinates stored in gdf\n",
    "\toutfn - outpath\n",
    "\t'''\n",
    "\t\n",
    "\txmin, ymin = gdf.bounds.minx.values[0], gdf.bounds.miny.values[0]\n",
    "\txmax, ymax = gdf.bounds.maxx.values[0], gdf.bounds.maxy.values[0]\n",
    "\tnrows, ncols = array.shape\n",
    "\txres = (xmax-xmin)/float(ncols)\n",
    "\tyres = (ymax-ymin)/float(nrows)\n",
    "\tgeotransform =(xmin,xres,0,ymax,0, -yres)   \n",
    "\n",
    "\toutput_raster = gdal.GetDriverByName('GTiff').Create(outfn,ncols, nrows, 1 , gdal.GDT_Float32)  # Open the file\n",
    "\toutput_raster.SetGeoTransform(geotransform)  # Specify coords\n",
    "\tsrs = osr.SpatialReference()                 # Establish encoding\n",
    "\tsrs.ImportFromEPSG(4326)                     # WGS84 lat long\n",
    "\toutput_raster.SetProjection(srs.ExportToWkt() )   # Export coordinate system \n",
    "\toutput_raster.GetRasterBand(1).WriteArray(array)   # Write array to raster\n",
    "\t\n",
    "\tprint(\"wrote {}\".format(outfn))\n",
    "\treturn outfn\n",
    "\n",
    "def get_fnf(stn_id):\n",
    "    '''\n",
    "    Query CA DWR website to get reservoir storage for an area of interest\n",
    "    '''\n",
    "    print(\"**** Fetching FNF for {} ****\".format(stn_id))\n",
    "\n",
    "    url = \"https://cdec.water.ca.gov/dynamicapp/req/CSVDataServlet?Stations={}&SensorNums=8&dur_code=D&Start=2000-09-01&End=2021-09-01\".format(stn_id)\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "    df[stid] = pd.to_numeric(df['VALUE'], errors='coerce').interpolate(how = 'linear') * 0.0283168 # cfs --> cms \n",
    "    df.index = pd.to_datetime(df['DATE TIME'])\n",
    "    df.index.names = ['date']\n",
    "    df.drop(['STATION_ID', \"VALUE\", \"DURATION\", \"SENSOR_NUMBER\", \n",
    "             \"SENSOR_TYPE\", \"OBS DATE\",'DATE TIME', \"DATA_FLAG\", \"UNITS\"], axis = 1, inplace = True)\n",
    "\n",
    "    df[df[stid] < 0] = np.nan\n",
    "    return df#.interpolate(how = 'polynomial', order = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94094dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5e4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c19cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "\treturn(x-np.nanmin(x))/(np.nanmax(x)- np.nanmin(x))\n",
    "\n",
    "def standardize(x):\n",
    "    scaled = (x - np.nanmean(x)) / np.nanstd(x);\n",
    "    scaled[np.isnan(x)] = 0\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def calc_TE(imstack, qarr, K):\n",
    "    \n",
    "    imgmean = np.nanmean(imstack, axis = 2)\n",
    "    b=qarr.copy()\n",
    "    \n",
    "    rows, cols, time = imstack.shape\n",
    "    px_ts = []\n",
    "    rclist = []\n",
    "\n",
    "    # extract pixelwise timeseries\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            \n",
    "            ts_arr = imstack[row,col,:]\n",
    "            \n",
    "            if imgmean[row,col] == np.nan:\n",
    "                continue\n",
    "\n",
    "            ts_arr[np.isnan(ts_arr)] = 0\n",
    "            px_ts.append(pd.Series(ts_arr))\n",
    "            rclist.append([row,col])\n",
    "\n",
    "    pxdf = pd.concat(px_ts, axis = 1)\n",
    "    pxdf.columns = pxdf.columns.map(str)\n",
    "\n",
    "    # Build the out image\n",
    "    corrim = np.zeros_like(np.mean(imstack, axis = 2))\n",
    "\n",
    "    # Populate the per-pixel lags \n",
    "    for rc, dfcolidx in tqdm(list(zip(rclist,pxdf.columns))[:]):\n",
    "\n",
    "        a=pxdf[dfcolidx].values\n",
    "        days_window = K\n",
    "        if not np.all(a==0):\n",
    "            trans_ent = te.te_compute(a,b,k=3,embedding = K)\n",
    "        else:\n",
    "            trans_ent = np.nan\n",
    "\n",
    "        # fill ims\n",
    "        rowidx, colidx = rc\n",
    "        corrim[rowidx,colidx] = trans_ent\n",
    "        \n",
    "    return corrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12db00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(stid):\n",
    "    \n",
    "    # Read table 1\n",
    "    t1df = pd.read_csv(\"../data/Table1.csv\")\n",
    "    t1df.drop(columns=t1df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    # Read rainfall and snowmelt data\n",
    "    smlt_fn_1d = \"../data/Watersheds/smlt/{}_smlt.npy\".format(stid)\n",
    "    prcp_fn_1d = \"../data/Watersheds/prcp/{}_1d_prcp.npy\".format(stid)\n",
    "\n",
    "    # Read runoff\n",
    "    bf = pd.read_csv(\"../data/baseflow_sep/baseflow_mm.csv\")\n",
    "    bf['date'] = pd.to_datetime(bf['date'])\n",
    "    bf.set_index(\"date\", inplace = True)    \n",
    "    sr = pd.read_csv(\"../data/baseflow_sep/surface_runoff_mm.csv\")\n",
    "    sr['date'] = pd.to_datetime(sr['date'])\n",
    "    sr.set_index(\"date\", inplace = True)   \n",
    "\n",
    "    # Load files as np arrays\n",
    "    smlt = np.load(smlt_fn_1d)\n",
    "    smlt = smlt*100 # apply scaling factor \n",
    "    prcp = np.load(prcp_fn_1d)\n",
    "\n",
    "    qarr = bf[stid].values\n",
    "    if int(t1df[t1df['id'] ==stid]['K']) > 39:\n",
    "        K = int(t1df[t1df['id'] ==stid]['K']) \n",
    "    else:\n",
    "        K=55\n",
    "        \n",
    "    pr_te = None \n",
    "    \n",
    "    outdir = \"../results/BF_te\"\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    if not os.path.exists(os.path.join(outdir,\"{}_prcp.tif\".format(stid))):\n",
    "        pr_te = calc_TE(prcp, qarr, K)\n",
    "        write_raster(pr_te, gp.read_file(\"../shape/{}.shp\".format(stid)), os.path.join(outdir,\"{}_prcp.tif\".format(stid)))\n",
    "    if not os.path.exists(os.path.join(outdir,\"{}_smlt.tif\".format(stid))):\n",
    "        sm_te = calc_TE(smlt, qarr, K)\n",
    "        write_raster(sm_te, gp.read_file(\"../shape/{}.shp\".format(stid)), os.path.join(outdir,\"{}_smlt.tif\".format(stid)))\n",
    "    \n",
    "    if pr_te is not None:\n",
    "        plt.figure(figsize = (15,5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(pr_te); plt.colorbar()\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(sm_te); plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972ef9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJF\n",
      "PROCESSING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c29d9edccc2d>:12: RuntimeWarning: Mean of empty slice\n",
      "  imgmean = np.nanmean(imstack, axis = 2)\n",
      "100%|██████████| 12649/12649 [32:20:09<00:00,  9.20s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote ../results/BF_te_final/SJF_prcp.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c29d9edccc2d>:12: RuntimeWarning: Mean of empty slice\n",
      "  imgmean = np.nanmean(imstack, axis = 2)\n",
      " 26%|██▌       | 3280/12649 [54:46<11:24:39,  4.38s/it]"
     ]
    }
   ],
   "source": [
    "for stid in list(gdf['stid'][:]):\n",
    "    \n",
    "    print(stid)\n",
    "\n",
    "    # Read table 1\n",
    "    t1df = pd.read_csv(\"../data/Table1.csv\")\n",
    "    t1df.drop(columns=t1df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    # Read rainfall and snowmelt data\n",
    "    smlt_fn_1d = \"../data/Watersheds/smlt/{}_smlt.npy\".format(stid)\n",
    "    prcp_fn_1d = \"../data/Watersheds/prcp/{}_1d_prcp.npy\".format(stid)\n",
    "\n",
    "    # Read runoff\n",
    "    bf = pd.read_csv(\"../data/baseflow_sep/baseflow_mm.csv\")\n",
    "    bf['date'] = pd.to_datetime(bf['date'])\n",
    "    bf.set_index(\"date\", inplace = True)    \n",
    "    sr = pd.read_csv(\"../data/baseflow_sep/surface_runoff_mm.csv\") \n",
    "    sr['date'] = pd.to_datetime(sr['date'])\n",
    "    sr.set_index(\"date\", inplace = True)   \n",
    "\n",
    "    # Load files as np arrays\n",
    "    smlt = np.load(smlt_fn_1d)\n",
    "    smlt = smlt*100 # apply scaling factor \n",
    "    prcp = np.load(prcp_fn_1d)\n",
    "\n",
    "    qarr = bf[stid].values[:-1]\n",
    "    if int(t1df[t1df['id'] ==stid]['K']) > 39:\n",
    "        K = int(t1df[t1df['id'] ==stid]['K']) \n",
    "    else:\n",
    "        K=55\n",
    "        \n",
    "    pr_te = None \n",
    "    \n",
    "    outdir = \"../results/BF_te_final\"\n",
    "    \n",
    "    print(\"PROCESSING\")\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "        \n",
    "    # write if doesn't exist, read if it does \n",
    "    if not os.path.exists(os.path.join(outdir,\"{}_prcp.tif\".format(stid))):\n",
    "        pr_te = calc_TE(prcp, qarr, K)\n",
    "        write_raster(pr_te, gp.read_file(\"../shape/{}.shp\".format(stid)), os.path.join(outdir,\"{}_prcp.tif\".format(stid)))\n",
    "    else:\n",
    "        pr_te = rio.open(os.path.join(outdir,\"{}_smlt.tif\".format(stid))).read(1)\n",
    "    \n",
    "    # write if doesn't exist, read if it does \n",
    "    if not os.path.exists(os.path.join(outdir,\"{}_smlt.tif\".format(stid))):\n",
    "        sm_te = calc_TE(smlt, qarr, K)\n",
    "        write_raster(sm_te, gp.read_file(\"../shape/{}.shp\".format(stid)), os.path.join(outdir,\"{}_smlt.tif\".format(stid)))\n",
    "    else:\n",
    "        sm_te = rio.open(os.path.join(outdir,\"{}_smlt.tif\".format(stid))).read(1)\n",
    "    \n",
    "    plt.figure(figsize = (15,5))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(pr_te); plt.colorbar()\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(sm_te); plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bf7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
